
Some labs to study distributed systems:

## Lab1: MapReduce


### Prepared

A simple sequential mapreduce implementation: 
    src/main/mrsequential.go. 
A couple of MapReduce applications: 
    word-count in mrapps/wc.go, and a text indexer in mrapps/indexer.go. 

```
go build -buildmode=plugin ../mrapps/wc.go
rm mr-out*
go run mrsequential.go wc.so pg*.txt
more mr-out-0
```

### TODO

To implement a distributed MapReduce, consisting of two programs, the master and the worker. 

```
go build -buildmode=plugin ../mrapps/wc.go
```

In the main directory, run the master.
```
rm mr-out*
go run mrmaster.go pg-*.txt
```

In one or more other windows, run some workers:
```
go run mrworker.go wc.so
```

### Paper: MapReduce: Simplified Data Processing on Large Clusters

When the user program calls the $MapReduce$ function, the following sequence of actions occurs: 
    1. The MapReduce library in the user program first splits the input files into $M$ pieces of typically 16 megabytes to 64 megabytes (MB) per piece. 
    2. One of the copies of the program is special Ã±the master. 
    3. A worker who is assigned a map task reads the contents of the corresponding input split. 
    4. Periodically, the buffered pairs are written to local disk, partitioned into R regions by the partitioning function. 
    5. When a reduce worker is notified by the master about these locations, it uses remote procedure calls to read the buffered data from the local disks of the map workers. 
    6. The reduce worker iterates over the sorted intermediate data and for each unique intermediate keyencountered, itpasses the keyand the corresponding set of intermediate values tothe user's Reduce function. 
    7. When all map tasks and reduce tasks have been completed, the master wakes up the user program. At this point, the MapReduce call in the user program returns back to the user code.

Modify the mrmaster.go. 


## Lab2: Raft

## Lab3: Fault-tolerant Key/Value Service

## Lab4: Sharded Key/Value Service

